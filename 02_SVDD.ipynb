{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install IPython\n",
    "from IPython.display import display, HTML, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/KU-DIC/LG_time_series_day15.git #코랩 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [시계열 이상치 탐지 3 실습]\n",
    "# SVDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### jupyter notebook 단축키\n",
    "\n",
    "- ctrl+enter: 셀 실행   \n",
    "- shift+enter: 셀 실행 및 다음 셀 이동   \n",
    "- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n",
    "- a: 상단에 새로운 셀 만들기\n",
    "- b: 하단에 새로운 셀 만들기\n",
    "- dd: 셀 삭제(x: 셀 삭제)\n",
    "- 함수 ( ) 안에서 shift+tab: arguments description. shift+tab+tab은 길게 볼 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __1. Support Vector Data Description (SVDD)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Data Description (SVDD)\n",
    ">SVDD의 목표는 Data를 feature space로 mapping 한 뒤, normal data들의 영역을 포함할 수 있는 가장 작은 Hypersphere를 찾는 것 <br>\n",
    ">학습: Find a hypersphere enclosing all the normal instances in a feature space <br>\n",
    "> 테스트: 새로운 데이터에 대하여 학습된 원을 넘으면 이상치에 가까운 것으로 판정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_time_series_day15/image/intro3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/LG_time_series_day15/src/')\n",
    "\n",
    "from svdd import SVDD\n",
    "from visualize import Visualization as draw\n",
    "from data import PrepareData as load\n",
    "\n",
    "''' 기본 모듈 및 시각화 모듈 '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>__1. Data: Iris Dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data =  preprocessing.StandardScaler().fit_transform(iris.data)\n",
    "label = iris.target\n",
    "\n",
    "p_data = data[label == 0, :]\n",
    "n_data = data[label != 0, :]\n",
    "#{0:\"setosa\", 1:\"versicolor\", 2:\"virginica\"}\n",
    "\n",
    "\"\"\" 레이블을 (1, -1)로 변경해야 합 \"\"\"\n",
    "p_label = np.mat(np.ones(p_data.shape[0])).T\n",
    "n_label = np.mat(-np.ones(n_data.shape[0])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. 데이터 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x, p_xt, p_y, p_yt = train_test_split(p_data, p_label, test_size=0.3, random_state=1)\n",
    "n_x, n_xt, n_y, n_yt = train_test_split(n_data, n_label, test_size=0.9, random_state=1)\n",
    "        \n",
    "trainData = np.vstack((p_x, n_x))\n",
    "testData = np.vstack((p_xt, n_xt))\n",
    "trainLabel = np.vstack((p_y, n_y))\n",
    "testLabel = np.vstack((p_yt, n_yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Base SVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SVDD parameters\n",
    "parameters = {\"positive penalty\": 0.9,\n",
    "              \"negative penalty\": 0.8,\n",
    "              \"kernel\": {\"type\": 'gauss', \"width\": 1/24},\n",
    "              \"option\": {\"display\": 'on'}}\n",
    "\n",
    "\n",
    "# construct an SVDD model\n",
    "svdd = SVDD(parameters)\n",
    "\n",
    "# train SVDD model\n",
    "svdd.train(trainData, trainLabel)\n",
    "\n",
    "# test SVDD model\n",
    "distance, accuracy = svdd.test(testData, testLabel)\n",
    "\n",
    "# visualize the results\n",
    "draw.testResult(svdd, distance)\n",
    "draw.testROC(testLabel, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. kernel function에 따른 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/LG_time_series_day15/image/intro4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kernel list\n",
    "kernelList = {\"1\": {\"type\": 'gauss', \"width\": 1/24},\n",
    "              \"2\": {\"type\": 'linear', \"offset\": 0},\n",
    "              \"3\": {\"type\": 'ploy', \"degree\": 2, \"offset\": 0},\n",
    "              \"4\": {\"type\": 'tanh', \"gamma\": 1e-4, \"offset\": 0},\n",
    "              \"5\": {\"type\": 'lapl', \"width\": 1/12}\n",
    "              }\n",
    "\n",
    "for i in range(len(kernelList)):\n",
    "\n",
    "    # set SVDD parameters\n",
    "    parameters = {\"positive penalty\": 0.9,\n",
    "                  \"negative penalty\": 0.8,\n",
    "                  \"kernel\": kernelList.get(str(i+1)),\n",
    "                  \"option\": {\"display\": 'on'}}\n",
    "    \n",
    "    # construct an SVDD model\n",
    "    svdd = SVDD(parameters)\n",
    "    \n",
    "    # train SVDD model\n",
    "    svdd.train(trainData, trainLabel)\n",
    "      \n",
    "    # test SVDD model\n",
    "    distance, accuracy = svdd.test(testData, testLabel)\n",
    "    draw.testResult(svdd, distance)\n",
    "    draw.testROC(testLabel, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>__2. Data: Example. SVDD with dataset1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df= pd.read_csv('/content/LG_time_series_day15/data/dataset1.csv',header=None)\n",
    "\n",
    "df.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"Class\"]\n",
    "\n",
    "data = df.iloc[:,:-1]\n",
    "label = df.iloc[:,[-1]]\n",
    "\n",
    "p_data = data[label['Class']==0]\n",
    "n_data = data[label['Class'] != 0]\n",
    "\n",
    "p_label = np.mat(np.ones(p_data.shape[0])).T\n",
    "n_label = np.mat(-np.ones(n_data.shape[0])).T\n",
    "        \n",
    "p_x, p_xt, p_y, p_yt = train_test_split(p_data, p_label, test_size=0.3, random_state=1)\n",
    "n_x, n_xt, n_y, n_yt = train_test_split(n_data, n_label, test_size=0.9, random_state=1)\n",
    "        \n",
    "trainData = np.vstack((p_x, n_x))\n",
    "testData = np.vstack((p_xt, n_xt))\n",
    "trainLabel = np.vstack((p_y, n_y))\n",
    "testLabel = np.vstack((p_yt, n_yt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SVDD parameters\n",
    "parameters = {\"positive penalty\": 0.9,\n",
    "              \"negative penalty\": 0.8,\n",
    "              \"kernel\": {\"type\": 'gauss', \"width\": 1/24},\n",
    "              \"option\": {\"display\": 'on'}}\n",
    "\n",
    "\n",
    "# construct an SVDD model\n",
    "svdd = SVDD(parameters)\n",
    "\n",
    "# train SVDD model\n",
    "svdd.train(trainData, trainLabel)\n",
    "\n",
    "# test SVDD model\n",
    "distance, accuracy = svdd.test(testData, testLabel)\n",
    "\n",
    "# visualize the results\n",
    "draw.testResult(svdd, distance)\n",
    "draw.testROC(testLabel, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>__3. Data: NASA Bearing Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "data= pd.read_csv('/content/LG_time_series_day15/data/nasa_bearing_dataset.csv', index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data['data_type'] == 'train'].iloc[:, :4]\n",
    "y_train = data[data['data_type'] == 'train'].iloc[:, -2].values\n",
    "\n",
    "X_test = data[data['data_type'] == 'test'].iloc[:, :4]\n",
    "y_test = data[data['data_type'] == 'test'].iloc[:, -2].values\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 기반으로 train/test 데이터에 대하여 standard scaling 적용 (평균 0, 분산 1) \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), \n",
    "                              columns=X_train.columns, \n",
    "                              index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), \n",
    "                             columns=X_test.columns, \n",
    "                             index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train (0,1) -> train_label (1.-1)로 변경\n",
    "train_label = []\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        train_label.append(1)\n",
    "    else:\n",
    "        train_label.append(-1)\n",
    "        \n",
    "train_label = np.array(train_label).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test (0,1) -> test_label (1.-1)로 변경\n",
    "test_label = []\n",
    "for i in y_test:\n",
    "    if i == 0:\n",
    "        test_label.append(1)\n",
    "    else:\n",
    "        test_label.append(-1)\n",
    "        \n",
    "test_label = np.array(test_label).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SVDD parameters\n",
    "parameters = {\"positive penalty\": 0.9,\n",
    "              \"negative penalty\": 0.8,\n",
    "              \"kernel\": {\"type\": 'gauss', \"width\": 1/24},\n",
    "              \"option\": {\"display\": 'on'}}\n",
    "\n",
    "\n",
    "# construct an SVDD model\n",
    "svdd = SVDD(parameters)\n",
    "\n",
    "# train SVDD model\n",
    "svdd.train(trainData, trainLabel)\n",
    "\n",
    "# test SVDD model\n",
    "distance, accuracy = svdd.test(testData, testLabel)\n",
    "\n",
    "# visualize the results\n",
    "draw.testResult(svdd, distance)\n",
    "draw.testROC(testLabel, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>__실습 과제 참고용(Data Import)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset2 적용\n",
    "\n",
    "df= pd.read_csv('/content/LG_time_series_day15/data/dataset2.csv',header=None)\n",
    "df.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"Class\"]\n",
    "\n",
    "\n",
    "data = df.iloc[:,:-1]\n",
    "label = df.iloc[:,[-1]]\n",
    "\n",
    "\n",
    "p_data = data[label['Class']==0]\n",
    "n_data = data[label['Class'] != 0]\n",
    "\n",
    "p_label = np.mat(np.ones(p_data.shape[0])).T\n",
    "n_label = np.mat(-np.ones(n_data.shape[0])).T\n",
    "        \n",
    "p_x, p_xt, p_y, p_yt = train_test_split(p_data, p_label, test_size=0.3, random_state=1)\n",
    "n_x, n_xt, n_y, n_yt = train_test_split(n_data, n_label, test_size=0.9, random_state=1)\n",
    "        \n",
    "trainData = np.vstack((p_x, n_x))\n",
    "testData = np.vstack((p_xt, n_xt))\n",
    "trainLabel = np.vstack((p_y, n_y))\n",
    "testLabel = np.vstack((p_yt, n_yt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
